{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_batch_normalization.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoneken1/colab_tensorflow/blob/master/tensorflow_batch_normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xXyCE1li7NKW"
      },
      "cell_type": "markdown",
      "source": [
        "# NGな実装\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "8kaGUlQZ7RMf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. tf.keras.batchnorm　＆　カスタムestimator"
      ]
    },
    {
      "metadata": {
        "id": "Dz7Ex5MG6tXE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def model_fn(features, labels, mode):\n",
        "  \n",
        "  training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  x = tf.keras.layers.BatchNormalization()(features,training=training)\n",
        "  y = tf.keras.layers.Dense(1)(x)\n",
        "  predictions = {\n",
        "      \"prob\": y,\n",
        "  }\n",
        "  \n",
        "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "  loss = tf.reduce_mean(tf.losses.mean_squared_error(labels,y))\n",
        "\n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "     \n",
        "      update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "      with tf.control_dependencies(update_ops):\n",
        "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
        "\n",
        "      return tf.estimator.EstimatorSpec(\n",
        "          mode=tf.estimator.ModeKeys.TRAIN,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "    \n",
        "  return tf.estimator.EstimatorSpec(\n",
        "      mode=mode, loss=loss)\n",
        "  \n",
        "estimator = tf.estimator.Estimator(\n",
        "    model_fn=model_fn)\n",
        "\n",
        "input_fn = lambda:(tf.constant([[0], [1], [2], [3]], dtype=tf.float32),tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32))\n",
        "\n",
        "estimator.train(input_fn,steps=5000)\n",
        "result = estimator.evaluate(input_fn,steps=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wQr56Hrb6xMY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# OKな実装\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "UibhEKh1_A-4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "tf.layers.BatchNormalziation　＆　カスタムestimator"
      ]
    },
    {
      "metadata": {
        "id": "NcaXlIW96wGZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def model_fn(features, labels, mode):\n",
        "  \n",
        "  training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  x = tf.layers.BatchNormalization()(features,training=training)\n",
        "  y = tf.keras.layers.Dense(1)(x)\n",
        "  predictions = {\n",
        "      \"prob\": y,\n",
        "  }\n",
        "  \n",
        "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "  loss = tf.reduce_mean(tf.losses.mean_squared_error(labels,y))\n",
        "\n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "     \n",
        "      update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "      with tf.control_dependencies(update_ops):\n",
        "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
        "\n",
        "      return tf.estimator.EstimatorSpec(\n",
        "          mode=tf.estimator.ModeKeys.TRAIN,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "    \n",
        "  return tf.estimator.EstimatorSpec(\n",
        "      mode=mode, loss=loss)\n",
        "  \n",
        "estimator = tf.estimator.Estimator(\n",
        "    model_fn=model_fn)\n",
        "\n",
        "input_fn = lambda:(tf.constant([[0], [1], [2], [3]], dtype=tf.float32),tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32))\n",
        "\n",
        "estimator.train(input_fn,steps=5000)\n",
        "result = estimator.evaluate(input_fn,steps=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JD6xx6_g_KZW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "tf.keras.layers.BatchNormaliztion　＆　model_to_estimator"
      ]
    },
    {
      "metadata": {
        "id": "bH8kRp46_dhV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "inputs = tf.keras.Input(shape=(1,))\n",
        "x = tf.keras.layers.BatchNormalization()(inputs)\n",
        "outputs = tf.keras.layers.Dense(1)(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mse',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "estimator = tf.keras.estimator.model_to_estimator(model)\n",
        "\n",
        "input_fn = lambda:(tf.constant([[0], [1], [2], [3]], dtype=tf.float32),tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32))\n",
        "\n",
        "estimator.train(input_fn,steps=5000)\n",
        "result = estimator.evaluate(input_fn,steps=4)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZCn7HqoKk1qi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Traditional style sample"
      ]
    },
    {
      "metadata": {
        "id": "SVjFbng8CoHR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "fb9fce78-02c6-4cd7-aca5-900286258706"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "tf.reset_default_graph()\n",
        "inputs = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
        "labels = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
        "training = tf.placeholder(shape=[], dtype=tf.bool)\n",
        "\n",
        "with tf.variable_scope('batch_normalization_test'):\n",
        "  with tf.name_scope('for_train'):\n",
        "    BN1 =  tf.layers.BatchNormalization(name=\"bn1\")\n",
        "    x = BN1(inputs,training =training)\n",
        "    x = tf.layers.Dense(units=1,name=\"dense1\")(x)\n",
        "    BN2 =  tf.layers.BatchNormalization(name=\"bn2\")\n",
        "    x = BN2(x,training =training)\n",
        "    output1 = tf.layers.Dense(units=1,name=\"dense2\")(x)\n",
        "\n",
        "with tf.variable_scope('batch_normalization_test', reuse=True):\n",
        "  with tf.name_scope('for_test'):\n",
        "    BN1 =  tf.layers.BatchNormalization(name=\"bn1\")\n",
        "    x = BN1(inputs,training =training)\n",
        "    x = tf.layers.Dense(units=1,name=\"dense1\")(x)\n",
        "    BN2 =  tf.layers.BatchNormalization(name=\"bn2\")\n",
        "    x = BN2(x,training =training)\n",
        "    output2 = tf.layers.Dense(units=1,name=\"dense2\")(x)\n",
        "\n",
        "loss = tf.reduce_mean(tf.losses.mean_squared_error(labels,output1))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "grads = optimizer.compute_gradients(loss)\n",
        "with tf.control_dependencies(update_ops):\n",
        "  train_op = optimizer.apply_gradients(grads)\n",
        "\n",
        "  sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "train_x = np.array([[-3.],[-2.],[-1.],[0.]])\n",
        "train_y = np.array([[0.], [1.], [2.], [3.]])\n",
        "\n",
        "for _ in range(5000):\n",
        "  sess.run((loss,train_op,output1,output2),{inputs:train_x,labels:train_y,training:True})\n",
        "#  print(sess.run(BN1.weights))\n",
        "#  print(sess.run(BN2.weights))\n",
        "\n",
        "print(sess.run((loss,output1,output2),{inputs:train_x,labels:train_y,training:True}))\n",
        "print(sess.run((output1),{inputs:train_x,training:False}))\n",
        "print(sess.run((output2),{inputs:train_x,training:False}))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1.43538514e-11, array([[6.2584877e-06],\n",
            "       [1.0000033e+00],\n",
            "       [2.0000005e+00],\n",
            "       [2.9999974e+00]], dtype=float32), array([[6.2584877e-06],\n",
            "       [1.0000033e+00],\n",
            "       [2.0000005e+00],\n",
            "       [2.9999974e+00]], dtype=float32))\n",
            "[[-1.6331673e-05]\n",
            " [ 9.9998498e-01]\n",
            " [ 1.9999862e+00]\n",
            " [ 2.9999876e+00]]\n",
            "[[-1.6331673e-05]\n",
            " [ 9.9998498e-01]\n",
            " [ 1.9999862e+00]\n",
            " [ 2.9999876e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LM6oahrBmfsN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}